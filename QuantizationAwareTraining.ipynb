{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOkKtWTPkWWe1dBZQQx1MHJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kalyaannnn/TransforMER/blob/main/QuantizationAwareTraining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "I0cEfNn6s6dH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = torch.manual_seed(0)"
      ],
      "metadata": {
        "id": "610D6KYetVUd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307, ), (0.3081, ))])"
      ],
      "metadata": {
        "id": "u03LMKWNtwy_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_trainset = datasets.MNIST(root = './data', download = True, train = True, transform = transform)\n",
        "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size = 10, shuffle = True)\n",
        "\n",
        "mnist_testset = datasets.MNIST(root = './data', download = True, train = False, transform = transform)\n",
        "test_loader = torch.utils.data.DataLoader(mnist_testset, batch_size = 10, shuffle = True)"
      ],
      "metadata": {
        "id": "O6wGRJ9NuSzw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAFbhIVBu9ga",
        "outputId": "4192b5de-db54-4127-c0f4-d8d01b774cca"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class QuantizedNet(nn.Module):\n",
        "  def __init__(self, hidden_size_1 = 100, hidden_size_2 = 100):\n",
        "    super(QuantizedNet, self).__init__()\n",
        "    self.quant = torch.quantization.QuantStub()\n",
        "    self.linear1 = nn.Linear(28*28, hidden_size_1)\n",
        "    self.linear2 = nn.Linear(hidden_size_1, hidden_size_2)\n",
        "    self.linear3 = nn.Linear(hidden_size_2, 10)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.dequant = torch.quantization.DeQuantStub()\n",
        "\n",
        "  def forward(self, img):\n",
        "    x = img.view(-1, 28*28)\n",
        "    x = self.quant(x)\n",
        "    x = self.relu(self.linear1(x))\n",
        "    x = self.relu(self.linear2(x))\n",
        "    x = self.linear3(x)\n",
        "    x = self.dequant(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "FKfKT5M2vOoE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = QuantizedNet().to(device)"
      ],
      "metadata": {
        "id": "1hP3GimGvXWe"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net.qconfig = torch.ao.quantization.default_qconfig\n",
        "net.train()\n",
        "net_quantized = torch.ao.quantization.prepare_qat(net)\n",
        "net_quantized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKxcQYu4vZ-x",
        "outputId": "a4f27511-b824-4561-86b7-5ec49fdbbc62"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "QuantizedNet(\n",
              "  (quant): QuantStub(\n",
              "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "  )\n",
              "  (linear1): Linear(\n",
              "    in_features=784, out_features=100, bias=True\n",
              "    (weight_fake_quant): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "  )\n",
              "  (linear2): Linear(\n",
              "    in_features=100, out_features=100, bias=True\n",
              "    (weight_fake_quant): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "  )\n",
              "  (linear3): Linear(\n",
              "    in_features=100, out_features=10, bias=True\n",
              "    (weight_fake_quant): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "  )\n",
              "  (relu): ReLU()\n",
              "  (dequant): DeQuantStub()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_loader, net, epochs = 5, total_iterations_limit = None):\n",
        "  cross_el = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.Adam(net.parameters(), lr = 0.001)\n",
        "\n",
        "  total_iterations = 0\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    net.train()\n",
        "\n",
        "    loss_sum = 0\n",
        "    num_iterations = 0\n",
        "\n",
        "    data_iterator = tqdm(train_loader, desc = f\"Epoch {epoch + 1}\")\n",
        "    if total_iterations_limit is not None:\n",
        "      data_iterator.total = total_iterations_limit\n",
        "    for data in data_iterator:\n",
        "      num_iterations += 1\n",
        "      total_iterations += 1\n",
        "      x, y = data\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      output = net(x.view(-1, 28*28))\n",
        "      loss = cross_el(output, y)\n",
        "      loss_sum += loss.item()\n",
        "      avg_loss = loss_sum / num_iterations\n",
        "      data_iterator.set_postfix(loss = avg_loss)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      if total_iterations_limit is not None and total_iterations >= total_iterations_limit:\n",
        "        return\n",
        "\n",
        "\n",
        "def print_size_of_model(model):\n",
        "  torch.save(model.state_dict(), \"temp_delme.p\")\n",
        "  print('Size (KB) :', os.path.getsize(\"temp_delme.p\")/1e3)\n",
        "  os.remove('temp_delme.p')"
      ],
      "metadata": {
        "id": "fnEgeUSTwIEO"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iXX1tczSx9MN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train(train_loader, net_quantized, epochs = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usVhX_dsx0PC",
        "outputId": "425b8eba-6c1a-427e-d21c-1d57684d0f02"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 6000/6000 [00:47<00:00, 127.01it/s, loss=0.22]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model : nn.Module, total_iterations : int = None):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  iterations = 0\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for data in tqdm(test_loader, desc = 'Testing'):\n",
        "      x, y = data\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "      output = model(x.view(-1, 784))\n",
        "      for idx, i in enumerate(output):\n",
        "        if(torch.argmax(i) == y[idx]):\n",
        "          correct += 1\n",
        "        total += 1\n",
        "      iterations += 1\n",
        "      if total_iterations is not None and iterations >= total_iterations:\n",
        "        break\n",
        "\n",
        "  print(f\"Accuracy : {round(correct/total, 3)}\")"
      ],
      "metadata": {
        "id": "qrc9HlZPzb7M"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Stastics during training')\n",
        "net_quantized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xUc5nPXzht4",
        "outputId": "9db5a3f4-77d0-4f27-e208-80217798fd60"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stastics during training\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "QuantizedNet(\n",
              "  (quant): QuantStub(\n",
              "    (activation_post_process): MinMaxObserver(min_val=-0.4242129623889923, max_val=2.821486711502075)\n",
              "  )\n",
              "  (linear1): Linear(\n",
              "    in_features=784, out_features=100, bias=True\n",
              "    (weight_fake_quant): MinMaxObserver(min_val=-0.6093528270721436, max_val=0.33149316906929016)\n",
              "    (activation_post_process): MinMaxObserver(min_val=-45.35358810424805, max_val=30.954242706298828)\n",
              "  )\n",
              "  (linear2): Linear(\n",
              "    in_features=100, out_features=100, bias=True\n",
              "    (weight_fake_quant): MinMaxObserver(min_val=-0.47003060579299927, max_val=0.3765200674533844)\n",
              "    (activation_post_process): MinMaxObserver(min_val=-28.6861572265625, max_val=20.01570701599121)\n",
              "  )\n",
              "  (linear3): Linear(\n",
              "    in_features=100, out_features=10, bias=True\n",
              "    (weight_fake_quant): MinMaxObserver(min_val=-0.3520001769065857, max_val=0.2868342399597168)\n",
              "    (activation_post_process): MinMaxObserver(min_val=-30.697715759277344, max_val=22.732498168945312)\n",
              "  )\n",
              "  (relu): ReLU()\n",
              "  (dequant): DeQuantStub()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Testing the model after quantization')\n",
        "test(net_quantized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaeqKjlyz9A9",
        "outputId": "533b9375-d923-4423-87d3-8e6333b5ecfa"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing the model after quantization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 1000/1000 [00:04<00:00, 212.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy : 0.957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}